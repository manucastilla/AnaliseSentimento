{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Sentimento - Tweets de compania aérea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Importando as dependências do python\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funções para realizaçaõ da limpeza dos tweets E\n",
    "def stemmer(df):\n",
    "    # https://www.datacamp.com/community/tutorials/stemming-lemmatization-python?utm_source=adwords_ppc&utm_campaignid=1455363063&utm_adgroupid=65083631748&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=332602034358&utm_targetid=aud-299261629574:dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=1001773&gclid=Cj0KCQjws-OEBhCkARIsAPhOkIaz_Gl4LR3zdQUBErnFXQNyFuad-t0PO-0q2KsTqKRgqSNQilO19TcaAgcmEALw_wcB\n",
    "    # http://www.nltk.org/howto/portuguese_en.html\n",
    "    allstopwords = stopwords.words('english')\n",
    "    allstopwords.remove('not')\n",
    "    stemmer = RSLPStemmer()\n",
    "    ntxt = []\n",
    "    for i in df.split():\n",
    "        if not i in set(allstopwords):\n",
    "            ntxt += [stemmer.stem(i)]\n",
    "    return \" \".join(ntxt)\n",
    "\n",
    "def remove_symbols(df):\n",
    "    # removes links\n",
    "    # https://stackoverflow.com/questions/6718633/python-regular-expression-again-match-url\n",
    "    df = re.sub(r\"[^@#\\w\\s]\", \"\", df)\n",
    "    #doesnt remove @, #\n",
    "    df = re.sub(r\"((http | https)\\: \\/\\/)?[a-zA-Z0-9\\.\\/\\?\\: @\\-_=  # ]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*\",\n",
    "                \"\", df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def limpa_tudo(df):\n",
    "    df = remove_symbols(df)\n",
    "    df = stemmer(df)\n",
    "    df = df.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparando a base de dados para execução das análises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o database\n",
    "dataset = pd.read_csv('Tweets.csv')\n",
    "dataset = pd.DataFrame(dataset)\n",
    "tweets = dataset[['airline_sentiment','text']]\n",
    "yds = dataset['airline_sentiment']\n",
    "\n",
    "y = []\n",
    "for i in range(0,4000):\n",
    "    if yds[i] == \"positive\":\n",
    "        y.append(1)\n",
    "    elif yds[i] == \"neutral\":\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(-1)\n",
    "y = np.array(y)\n",
    "\n",
    "x = []\n",
    "for i in range(0, 4000):\n",
    "    tweet = tweets['text'][i]\n",
    "    tweet = limpa_tudo(tweet)\n",
    "    x.append(tweet)\n",
    "\n",
    "# Dividindo a base entre base de treinamento e teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise exploratória do database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vetoriando o dataset em Bag of Words e em TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVec = CountVectorizer(lowercase=True).fit(x_train)\n",
    "tfidfVec = TfidfVectorizer(use_idf=True, smooth_idf=True).fit(x_train)\n",
    "\n",
    "x_train_vec_bow = countVec.transform(x_train).toarray()\n",
    "x_train_vec_bow = np.array(x_train_vec_bow)\n",
    "x_test_vec_bow = countVec.transform(x_test).toarray()\n",
    "\n",
    "x_train_vec_tfidf = tfidfVec.transform(x_train)\n",
    "x_test_vec_tfidf = tfidfVec.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando resultados com o modelos Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score NB with alpha 1 and TfIdF is 0.6775\n",
      "Score NB with alpha 1 and BOW is 0.725\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=alpha)\n",
    "\n",
    "nb.fit(x_train_vec_tfidf, y_train)\n",
    "y_pred_tfidf = nb.predict(x_test_vec_tfidf)\n",
    "\n",
    "nb.fit(x_train_vec_bow, y_train)\n",
    "y_pred_bow = nb.predict(x_test_vec_bow)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred_tfidf)\n",
    "score_bow = accuracy_score(y_test, y_pred_bow)\n",
    "\n",
    "print(\"Score NB with alpha {0} and TfIdF is {1}\".format(alpha, score))\n",
    "print(\"Score NB with alpha {0} and BOW is {1}\".format(alpha, score_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score NB with alpha 0.01 and TfIdF is 0.7225\n",
      "Score NB with alpha 0.01 and BOW is 0.73125\n",
      "Score NB with alpha 0.1 and TfIdF is 0.72625\n",
      "Score NB with alpha 0.1 and BOW is 0.74\n",
      "Score NB with alpha 0.5 and TfIdF is 0.69625\n",
      "Score NB with alpha 0.5 and BOW is 0.75\n",
      "Score NB with alpha 1 and TfIdF is 0.6775\n",
      "Score NB with alpha 1 and BOW is 0.725\n",
      "Score NB with alpha 1.5 and TfIdF is 0.66625\n",
      "Score NB with alpha 1.5 and BOW is 0.71375\n",
      "Score NB with alpha 10 and TfIdF is 0.66\n",
      "Score NB with alpha 10 and BOW is 0.66375\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.01, 0.1, 0.5, 1, 1.5, 10]\n",
    "\n",
    "for alpha in alphas:\n",
    "    nb = MultinomialNB(alpha=alpha)\n",
    "\n",
    "    nb.fit(x_train_vec_tfidf, y_train)\n",
    "    y_pred_tfidf = nb.predict(x_test_vec_tfidf)\n",
    "\n",
    "    nb.fit(x_train_vec_bow, y_train)\n",
    "    y_pred_bow = nb.predict(x_test_vec_bow)\n",
    "\n",
    "    score = accuracy_score(y_test, y_pred_tfidf)\n",
    "    score_bow = accuracy_score(y_test, y_pred_bow)\n",
    "\n",
    "    print(\"Score NB with alpha {0} and TfIdF is {1}\".format(alpha, score))\n",
    "    print(\"Score NB with alpha {0} and BOW is {1}\".format(alpha, score_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando resultados com o modelo de regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with TfIdf is 0.76625\n",
      "Score with BOW is 0.75625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nicolas stegmann\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0,solver='lbfgs')\n",
    "clf.fit(x_train_vec_tfidf, y_train)\n",
    "y_pred_logistics = clf.predict(x_test_vec_tfidf)\n",
    "\n",
    "clf.fit(x_train_vec_bow, y_train)\n",
    "y_pred_logistics_bow = clf.predict(x_test_vec_bow)\n",
    "\n",
    "score_tfidf = accuracy_score(y_test, y_pred_logistics)\n",
    "score_bow = accuracy_score(y_test, y_pred_logistics_bow)\n",
    "\n",
    "print(\"Score with TfIdf is {0}\".format(score_tfidf))\n",
    "print(\"Score with BOW is {0}\".format(score_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando resultados com SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with TfIdf is 0.76\n",
      "Score with BOW is 0.7525\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC()\n",
    "svc.fit(x_train_vec_bow, y_train)\n",
    "y_pred_svc_bow = svc.predict(x_test_vec_bow)\n",
    "\n",
    "svc.fit(x_train_vec_tfidf, y_train)\n",
    "y_pred_svc_tfidf = svc.predict(x_test_vec_tfidf)\n",
    "\n",
    "score_tfidf = accuracy_score(y_test, y_pred_svc_bow)\n",
    "score_bow = accuracy_score(y_test, y_pred_svc_tfidf)\n",
    "\n",
    "print(\"Score with TfIdf is {0}\".format(score_tfidf))\n",
    "print(\"Score with BOW is {0}\".format(score_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression vs naivebayes vs svC\n",
    "\n",
    "#naive bayes da overfitting checar erro de treino parametro alpha\n",
    "#logistic regreersion parametro l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
